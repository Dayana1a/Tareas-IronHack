<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3 Leyes de la robótica</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Ubuntu+Condensed&display=swap" rel="stylesheet">
</head>
<body>
    <h1>
        3 Leyes de la robótica
    </h1>

        <div class="autor">
            <div class="bio">
                <strong>Isaac Asimov,</strong> un escritor y bioquímico ruso-estadounidense nacido el 2 de enero de 1920 y fallecido el 6 de abril de 1992.
                <br>
                <strong>"La violencia es el último recurso del incompetente"</strong>
                <br>
                Asimov fue uno de los escritores de ciencia ficción más influyentes del siglo XX, además de un prolífico divulgador científico. Es conocido por obras como la Saga de la Fundación y sus relatos de robots, en los que introdujo las Tres Leyes de la Robótica para regular el comportamiento de las máquinas inteligentes.
            </div>
            <div class="imagen"></div>
        </div>

        <p class="introduccion">
            Las Tres Leyes de la Robótica fueron creadas por Isaac Asimov para garantizar que los robots fueran seguros y obedientes a los humanos. Estas leyes están diseñadas para evitar que los robots se conviertan en una amenaza y para regular su comportamiento de manera lógica y ética.
        </p>
    <main>
        <div class="ley1">
            <h2>
                Un robot no hará daño a un ser humano ni permitirá, por inacción, que un ser humano sufra daño
            </h2>
            <div class="img1"></div>
            <div class="explicacion">
                <strong>La Primera Ley</strong> establece que un robot no puede dañar a un ser humano, ni permitir, por inacción, que un ser humano sufra daño. Esto significa que los robots deben proteger a las personas en todo momento. No solo tienen prohibido atacarlas, sino que también deben intervenir si ven que alguien está en peligro. Por ejemplo, si un robot presencia un accidente y puede evitar que una persona salga herida, tiene la obligación de hacerlo.
            </div>
        </div>

        <div class="ley2">
            <h2>
                Un robot debe obedecer las órdenes dadas por los seres humanos, excepto si entran en conflicto con la Primera Ley
            </h2>
            <div class="img2"></div>
            <div class="explicacion">
                <strong>La Segunda Ley</strong> dicta que un robot debe obedecer las órdenes dadas por los seres humanos, a menos que estas órdenes entren en conflicto con la Primera Ley. En otras palabras, los robots están programados para seguir instrucciones, pero no pueden cumplirlas si eso significa lastimar a alguien. Por ejemplo, si una persona ordena a un robot golpear a otra, este no podrá hacerlo, ya que estaría violando la Primera Ley.
            </div>
        </div>

        <div class="ley3">
            <h2>
                Un robot debe proteger su propia existencia en la medida en que esta protección no entre en conflicto con la Primera o la Segunda Ley
            </h2>
            <div class="img3"></div>
            <div class="explicacion">
                <strong>La Tercera Ley</strong> indica que un robot debe proteger su propia existencia, siempre que esta protección no entre en conflicto con la Primera o la Segunda Ley. Los robots pueden defenderse y evitar ser destruidos, pero no si eso implica desobedecer una orden de un humano o causar daño a una persona. Si un robot está en peligro de ser destruido, intentará evitarlo, pero solo si no pone en riesgo a nadie más.
            </div>
        </div>
    </main>
</body>
</html>